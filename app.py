import streamlit as st
import google.generativeai as genai

st.set_page_config(page_title="Minha IA", page_icon="ğŸ¤–", layout="wide")

# CSS estilo ChatGPT
st.markdown("""
<style>
    .stChatMessage {background-color: #f7f7f8; border-radius: 10px; padding: 15px;}
    header {visibility: hidden;}
    #MainMenu {visibility: hidden;}
    footer {visibility: hidden;}
</style>
""", unsafe_allow_html=True)

# Sidebar
with st.sidebar:
    st.title("âš™ï¸ ConfiguraÃ§Ãµes")
    modelo = st.selectbox("Modelo", ["gemini-1.5-flash", "gemini-1.5-pro"])
    temp = st.slider("Criatividade", 0.0, 2.0, 0.7)
    if st.button("ğŸ—‘ï¸ Limpar conversa"):
        st.session_state.msgs = []
        st.rerun()
    
    st.divider()
    st.caption("Powered by Google Gemini 1.5")

# Verificar e configurar API
if "GEMINI_API_KEY" not in st.secrets:
    st.error("âš ï¸ Chave API nÃ£o configurada!")
    st.info("Configure em: Settings â†’ Secrets no Streamlit Cloud")
    st.stop()

genai.configure(api_key=st.secrets["GEMINI_API_KEY"])

# Inicializar histÃ³rico
if "msgs" not in st.session_state:
    st.session_state.msgs = []

# TÃ­tulo
st.title("ğŸ’¬ Minha IA Personalizada")
st.caption("ğŸš€ Conversa inteligente com Gemini 1.5")

# Mostrar histÃ³rico
for msg in st.session_state.msgs:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

# Input do usuÃ¡rio
if prompt := st.chat_input("Digite sua mensagem..."):
    # Adicionar mensagem do usuÃ¡rio
    st.session_state.msgs.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)
    
    # Gerar resposta
    with st.chat_message("assistant"):
        with st.spinner("Pensando..."):
            try:
                # Criar modelo com configuraÃ§Ã£o
                model = genai.GenerativeModel(
                    model_name=modelo,
                    generation_config={
                        "temperature": temp,
                        "top_p": 0.95,
                        "top_k": 64,
                        "max_output_tokens": 8192,
                    }
                )
                
                # Converter histÃ³rico para formato correto
                history = []
                for m in st.session_state.msgs[:-1]:
                    role = "user" if m["role"] == "user" else "model"
                    history.append({
                        "role": role,
                        "parts": [{"text": m["content"]}]
                    })
                
                # Iniciar chat e enviar mensagem
                chat = model.start_chat(history=history)
                response = chat.send_message(prompt)
                
                resposta = response.text
                st.markdown(resposta)
                st.session_state.msgs.append({"role": "assistant", "content": resposta})
                
            except Exception as e:
                erro = str(e)
                st.error(f"âŒ Erro: {erro}")
                
                # Mensagens de ajuda especÃ­ficas
                if "404" in erro or "not found" in erro.lower():
                    st.warning("ğŸ”§ **SoluÃ§Ã£o:** O modelo nÃ£o estÃ¡ disponÃ­vel na sua regiÃ£o ou API key.")
                    st.info("âœ… Teste criar uma NOVA chave API em: https://aistudio.google.com/app/apikey")
                elif "quota" in erro.lower() or "limit" in erro.lower():
                    st.warning("ğŸ“Š VocÃª atingiu o limite de requisiÃ§Ãµes. Aguarde alguns minutos.")
                elif "api" in erro.lower():
                    st.warning("ğŸ”‘ Problema com a chave API. Verifique se estÃ¡ correta e ativa.")
                    st.code(st.secrets.get("GEMINI_API_KEY", "NÃ£o configurada")[:20] + "...")
